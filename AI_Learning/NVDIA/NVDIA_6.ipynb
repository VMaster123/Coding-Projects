{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0994a51-d3fe-4023-86b1-8a68c7b3f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/huggingface/pytorch-transformers/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5f4f4763147f8960420a9115ecdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenizer_config.json', max=49.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ead4028f774cabba163842bba51d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='config.json', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a73124a140c464382a2f82b59bc9c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='vocab.txt', max=213450.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a77f6d82e440eb8fce4f0938eb6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenizer.json', max=435797.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98ca1a4-fd29-44a8-b8a3-fca655632a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 146,\n",
       " 2437,\n",
       " 11838,\n",
       " 117,\n",
       " 1241,\n",
       " 1103,\n",
       " 3014,\n",
       " 1105,\n",
       " 186,\n",
       " 18413,\n",
       " 21961,\n",
       " 1348,\n",
       " 119,\n",
       " 102,\n",
       " 1327,\n",
       " 1912,\n",
       " 1104,\n",
       " 11838,\n",
       " 1202,\n",
       " 146,\n",
       " 2437,\n",
       " 136,\n",
       " 102]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = \"I understand equations, both the simple and quadratical.\"\n",
    "text_2 = \"What kind of equations do I understand?\"\n",
    "\n",
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b0b033-782a-4088-a382-68446e5ccf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'I',\n",
       " 'understand',\n",
       " 'equations',\n",
       " ',',\n",
       " 'both',\n",
       " 'the',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'q',\n",
       " '##uad',\n",
       " '##ratic',\n",
       " '##al',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'What',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'equations',\n",
       " 'do',\n",
       " 'I',\n",
       " 'understand',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([str(token) for token in indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154a42f0-58ac-4b29-afb0-7ffd33b4d82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] I understand equations, both the simple and quadratical. [SEP] What kind of equations do I understand? [SEP]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9378e5ad-71ba-40b1-a914-758bd3e820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token = 101\n",
    "sep_token = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8ad529-3b47-4103-bbf7-fdae36b74b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_ids(indexed_tokens):\n",
    "    segment_ids = []\n",
    "    segment_id = 0\n",
    "    for token in indexed_tokens:\n",
    "        if token == sep_token:\n",
    "            segment_id += 1\n",
    "        segment_ids.append(segment_id)\n",
    "    segment_ids[-1] -= 1  # Last [SEP] is ignored\n",
    "    return torch.tensor([segment_ids]), torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a7bb3c-d872-4698-93eb-74f65a0a0674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_tensors, tokens_tensor = get_segment_ids(indexed_tokens)\n",
    "segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48859707-858e-4516-b7db-2f069499929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f59dd0-f3d6-428d-ab61-c2c52dc74c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ac5ea3-d17b-4168-9dbc-9cd5f35cdeba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masked_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m indexed_tokens[\u001b[43mmasked_index\u001b[49m] \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mmask_token_id\n\u001b[1;32m      2\u001b[0m tokens_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([indexed_tokens])\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdecode(indexed_tokens)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masked_index' is not defined"
     ]
    }
   ],
   "source": [
    "indexed_tokens[masked_index] = tokenizer.mask_token_id\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "tokenizer.decode(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883ddeba-7048-43e3-9980-c51a213a441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d025b445cab047e29ed90cc8ac3efc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='model.safetensors', max=435755784.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "masked_lm_model = torch.hub.load('huggingface/pytorch-transformers', 'modelForMaskedLM', 'bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a6ac4d-a6e9-4a3e-a5a6-6292a6a47ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582da5c4-d02c-474b-a088-35a58dba5987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0005, -0.0416,  0.0131,  ..., -0.0039, -0.0335,  0.0150],\n",
       "        [ 0.0169, -0.0311,  0.0042,  ..., -0.0147, -0.0356, -0.0036],\n",
       "        [-0.0006, -0.0267,  0.0080,  ..., -0.0100, -0.0331, -0.0165],\n",
       "        ...,\n",
       "        [-0.0064,  0.0166, -0.0204,  ..., -0.0418, -0.0492,  0.0042],\n",
       "        [-0.0048, -0.0027, -0.0290,  ..., -0.0512,  0.0045, -0.0118],\n",
       "        [ 0.0313, -0.0297, -0.0230,  ..., -0.0145, -0.0525,  0.0284]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table = next(masked_lm_model.bert.embeddings.word_embeddings.parameters())\n",
    "embedding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced4310a-302b-40fc-9a26-bb78b07caa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28996, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b5a367-7fd3-4773-aff8-b40679fec0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ -7.3227,  -7.1947,  -7.3926,  ...,  -6.0100,  -5.7544,  -6.1663],\n",
       "         [ -7.8402,  -8.0616,  -7.8916,  ...,  -6.5215,  -6.3073,  -6.8117],\n",
       "         [ -7.5290,  -7.7294,  -7.5514,  ...,  -5.7504,  -5.5850,  -4.2405],\n",
       "         ...,\n",
       "         [ -6.8125,  -6.9280,  -7.1593,  ...,  -6.6268,  -4.8445,  -3.3929],\n",
       "         [-11.4017, -11.5903, -11.0830,  ..., -10.0579,  -8.2003, -10.3975],\n",
       "         [-12.9638, -13.2358, -13.1546,  ..., -10.3690, -11.4416, -10.5666]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = masked_lm_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74940cbe-44c4-440e-ac32-11abddc58cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 28996])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f07d676f-006a-4bcb-ae09-f3c60aa46daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'masked_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get the predicted token\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predicted_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(predictions[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[43mmasked_index\u001b[49m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      3\u001b[0m predicted_index\n",
      "\u001b[0;31mNameError\u001b[0m: name 'masked_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the predicted token\n",
    "predicted_index = torch.argmax(predictions[0][0], dim=1)[masked_index].item()\n",
    "predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e9ecff-8f4e-4cb8-ae2a-6b7349514547",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "predicted_token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
